{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change detection (invariant to angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) # should be True\n",
    "# t = torch.rand(10, 10).cuda()\n",
    "# print(t.device) # should be CUDA\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with saggital midpoint images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image_if_not_exist(directory, output_size=(256, 256)):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\"nii_mask.nii.gz\"):\n",
    "                # Construct input and output paths\n",
    "                input_path = os.path.join(root, filename)\n",
    "                output_path = os.path.join(root, os.path.splitext(filename)[0] + \"saggital_view\" + \".jpg\")\n",
    "\n",
    "                # Check if output image already exists\n",
    "                if os.path.exists(output_path):\n",
    "                    print(f\"Image {output_path} already exists, skipping...\") \n",
    "                    continue\n",
    "                # Saggital - 0, Coronal - 1, Axial - 2\n",
    "                # Load NIfTI data\n",
    "                nifti_data = nib.load(input_path)\n",
    "                image_data = nifti_data.get_fdata()\n",
    "\n",
    "                slice_index = image_data.shape[0] // 2\n",
    "                image_slice = image_data[slice_index, :, :]\n",
    "\n",
    "                # Normalize intensity values\n",
    "                min_intensity = np.min(image_slice)\n",
    "                max_intensity = np.max(image_slice)\n",
    "                image_slice_normalized = (image_slice - min_intensity) / (max_intensity - min_intensity)\n",
    "\n",
    "                # Resize the slice to the specified output size\n",
    "                image_slice_resized = np.array(Image.fromarray((image_slice_normalized * 255).astype(np.uint8)).resize(output_size))\n",
    "\n",
    "                # Convert to image format\n",
    "                image = Image.fromarray(image_slice_resized)\n",
    "\n",
    "                # Resize the image to the specified output size\n",
    "                image = image.resize(output_size)\n",
    "\n",
    "                # Save the image\n",
    "                image.save(output_path)\n",
    "                print(f\"Converted masked image {input_path} to {output_path} with size {output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ./data/raw/preop/BTC-preop/sub-PAT31/ses-preop/anat/sub-PAT31_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON09/ses-preop/anat/sub-CON09_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON03/ses-preop/anat/sub-CON03_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT25/ses-preop/anat/sub-PAT25_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT14/ses-preop/anat/sub-PAT14_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT05/ses-preop/anat/sub-PAT05_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON02/ses-preop/anat/sub-CON02_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT26/ses-preop/anat/sub-PAT26_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT16/ses-preop/anat/sub-PAT16_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT01/ses-preop/anat/sub-PAT01_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT24/ses-preop/anat/sub-PAT24_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT13/ses-preop/anat/sub-PAT13_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON06/ses-preop/anat/sub-CON06_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON01/ses-preop/anat/sub-CON01_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT02/ses-preop/anat/sub-PAT02_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON08/ses-preop/anat/sub-CON08_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT10/ses-preop/anat/sub-PAT10_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT19/ses-preop/anat/sub-PAT19_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON04/ses-preop/anat/sub-CON04_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT17/ses-preop/anat/sub-PAT17_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT27/ses-preop/anat/sub-PAT27_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT07/ses-preop/anat/sub-PAT07_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON11/ses-preop/anat/sub-CON11_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON07/ses-preop/anat/sub-CON07_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT15/ses-preop/anat/sub-PAT15_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT29/ses-preop/anat/sub-PAT29_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT08/ses-preop/anat/sub-PAT08_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON10/ses-preop/anat/sub-CON10_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT23/ses-preop/anat/sub-PAT23_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT20/ses-preop/anat/sub-PAT20_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT22/ses-preop/anat/sub-PAT22_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT06/ses-preop/anat/sub-PAT06_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON05/ses-preop/anat/sub-CON05_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT03/ses-preop/anat/sub-PAT03_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT11/ses-preop/anat/sub-PAT11_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT28/ses-preop/anat/sub-PAT28_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "dir = \"./data/raw/preop/BTC-preop\"\n",
    "output_size = (256, 256)  # Specify the desired output size\n",
    "convert_to_image_if_not_exist(dir, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ./data/raw/postop/BTC-postop/sub-CON09/ses-postop/anat/sub-CON09_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON03/ses-postop/anat/sub-CON03_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT25/ses-postop/anat/sub-PAT25_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT05/ses-postop/anat/sub-PAT05_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON02/ses-postop/anat/sub-CON02_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT26/ses-postop/anat/sub-PAT26_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT16/ses-postop/anat/sub-PAT16_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT01/ses-postop/anat/sub-PAT01_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT24/ses-postop/anat/sub-PAT24_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT13/ses-postop/anat/sub-PAT13_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON06/ses-postop/anat/sub-CON06_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT02/ses-postop/anat/sub-PAT02_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON08/ses-postop/anat/sub-CON08_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT10/ses-postop/anat/sub-PAT10_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON04/ses-postop/anat/sub-CON04_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT17/ses-postop/anat/sub-PAT17_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT07/ses-postop/anat/sub-PAT07_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON11/ses-postop/anat/sub-CON11_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON07/ses-postop/anat/sub-CON07_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT15/ses-postop/anat/sub-PAT15_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT08/ses-postop/anat/sub-PAT08_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON10/ses-postop/anat/sub-CON10_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT23/ses-postop/anat/sub-PAT23_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT20/ses-postop/anat/sub-PAT20_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT06/ses-postop/anat/sub-PAT06_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON05/ses-postop/anat/sub-CON05_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT03/ses-postop/anat/sub-PAT03_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT11/ses-postop/anat/sub-PAT11_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT28/ses-postop/anat/sub-PAT28_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "dir = \"./data/raw/postop/BTC-postop\"\n",
    "output_size = (256, 256)  # Specify the desired output size\n",
    "convert_to_image_if_not_exist(dir, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageSets(Dataset):\n",
    "    \"\"\"\n",
    "    Image dataset for each subject in the dataset\n",
    "    creating only 'correct' pairs for now\n",
    "    TODO: create 'incorrect' pairs\n",
    "\n",
    "    Works by passing preop or postop directory to the class\n",
    "    and finds the corresponding image in the other dir and labels\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for filename in files:\n",
    "                if filename.endswith(\"saggital_view.jpg\"):\n",
    "                    img_1 = Image.open(os.path.join(root, filename))\n",
    "                    ## finds the corresponding image in the other dir\n",
    "                    try:\n",
    "                        if \"preop\" in root:\n",
    "                            img_2 = Image.open(os.path.join(root.replace(\"preop\", \"postop\"), filename.replace(\"preop\", \"postop\")))\n",
    "                        else:\n",
    "                            img_2 = Image.open(os.path.join(root.replace(\"postop\", \"preop\"), filename.replace(\"postop\", \"preop\")))\n",
    "                        self.data.append((img_1, img_2, 1))\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"File not found for {filename}\")\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            img1_file = self.transform(self.data[idx][0])\n",
    "            img2_file = self.transform(self.data[idx][1])\n",
    "        return (img1_file, img2_file, self.data[idx][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found for sub-PAT31_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "File not found for sub-PAT14_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "File not found for sub-CON01_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "File not found for sub-PAT19_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "File not found for sub-PAT27_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "File not found for sub-PAT29_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "File not found for sub-PAT22_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n"
     ]
    }
   ],
   "source": [
    "default_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_data = imageSets(\"./data/raw/preop/BTC-preop\", transform=default_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_data.__getitem__(0)[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Define the architecture for the Siamese network\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(131072, 128)  # Adjust input size based on input dimensions\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Forward pass through the Siamese network\n",
    "        output1 = F.relu(self.bn1(self.conv1(input1)))\n",
    "        output1 = F.max_pool2d(output1, kernel_size=2, stride=2)\n",
    "        output1 = F.relu(self.bn2(self.conv2(output1)))\n",
    "        output1 = F.max_pool2d(output1, kernel_size=2, stride=2)\n",
    "        output1 = F.relu(self.bn3(self.conv3(output1)))\n",
    "        output1 = F.max_pool2d(output1, kernel_size=2, stride=2)\n",
    "        output1 = output1.view(output1.size(0), -1)\n",
    "        output1 = self.dropout(output1)\n",
    "        output1 = F.relu(self.fc1(output1))\n",
    "\n",
    "        output2 = F.relu(self.bn1(self.conv1(input2)))\n",
    "        output2 = F.max_pool2d(output2, kernel_size=2, stride=2)\n",
    "        output2 = F.relu(self.bn2(self.conv2(output2)))\n",
    "        output2 = F.max_pool2d(output2, kernel_size=2, stride=2)\n",
    "        output2 = F.relu(self.bn3(self.conv3(output2)))\n",
    "        output2 = F.max_pool2d(output2, kernel_size=2, stride=2)\n",
    "        output2 = output2.view(output2.size(0), -1)\n",
    "        output2 = self.dropout(output2)\n",
    "        output2 = F.relu(self.fc1(output2))\n",
    "\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, input1, input2, y):\n",
    "        diff = input1 - input2\n",
    "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        mdist = self.margin - dist\n",
    "        dist = torch.clamp(mdist, min=0.0)\n",
    "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "        loss = torch.sum(loss) / 2.0 / input1.size()[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Siamese network\n",
    "siamese_net = SiameseNetwork()\n",
    "# siamese_net = siamese_net.cuda()  # Move the network to GPU\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/1, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the Siamese network architecture\n",
    "\n",
    "\n",
    "# Train the Siamese network\n",
    "def train(siamese_net, loader,  optimizer, criterion, epochs=10):\n",
    "    siamese_net.train()\n",
    "    print(len(loader))\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (img1_set, img2_set, label) in enumerate(loader):\n",
    "            # img1_set = img1_set.cuda()\n",
    "            # img2_set = img2_set.cuda()\n",
    "            # label = label.cuda()\n",
    "\n",
    "            output1, output2 = siamese_net(img1_set, img2_set)\n",
    "            criterion = ContrastiveLoss()\n",
    "            loss = criterion(output1, output2, label)  # Add unsqueeze to match output shape\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "           #test\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(loader)}\")\n",
    "\n",
    "# Train the Siamese network\n",
    "train(siamese_net, train_loader,  optimizer, criterion, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with raw data (not images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_preop = nib.load(\"./data/raw/preop/sub-CON02_ses-preop_T1w.nii.gz\")\n",
    "# raw_postop = nib.load(\"./data/raw/postop/sub-CON02_ses-postop_T1w.nii.gz\")\n",
    "\n",
    "# proc_preop = nib.load(\"./data/processed/preop/fa.nii.gz\")\n",
    "# proc_postop = nib.load(\"./data/processed/postop/fa.nii.gz\")\n",
    "\n",
    "# # This apparently returns voxel level of the data\n",
    "# data_raw_preop= raw_preop.get_fdata()\n",
    "# data_raw_postop= raw_postop.get_fdata()\n",
    "\n",
    "# data_proc_preop= proc_preop.get_fdata()\n",
    "# data_proc_postop= proc_postop.get_fdata()\n",
    "\n",
    "# print(data_raw_preop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20693/2275318329.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  raw_pairs_tensor = torch.tensor(raw_pairs, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# def make_pairs():\n",
    "#     pass\n",
    "import sys\n",
    "\n",
    "mock_pairs = [(data_raw_preop, data_raw_postop), (data_raw_preop, data_raw_preop), (data_raw_postop, data_raw_postop)]\n",
    "mock_labels = [1, 0, 0]\n",
    "\n",
    "raw_pairs = mock_pairs\n",
    "raw_labels = mock_labels\n",
    "# Convert the processed data into PyTorch tensors\n",
    "raw_pairs_tensor = torch.tensor(raw_pairs, dtype=torch.float32)\n",
    "raw_labels_tensor = torch.tensor(raw_labels, dtype=torch.float32)\n",
    "print(sys.getsizeof(raw_pairs_tensor))\n",
    "# print(raw_pairs_tensor)\n",
    "\n",
    "# Create DataLoader for training\n",
    "# raw_dataset = TensorDataset(raw_pairs_tensor, raw_labels_tensor)\n",
    "# raw_loader = DataLoader(raw_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         self.subnetwork = SubNetwork(input_size, hidden_size, output_size)\n",
    "    \n",
    "#     def forward(self, input1, input2):\n",
    "#         # Pass inputs through the subnetwork\n",
    "#         output1 = self.subnetwork(input1)\n",
    "#         output2 = self.subnetwork(input2)\n",
    "        \n",
    "#         # Compute the Euclidean distance between the outputs\n",
    "#         distance = torch.sqrt(torch.sum(torch.pow(output1 - output2, 2), dim=1))\n",
    "        \n",
    "#         # Normalize the distance to [0, 1] range\n",
    "#         distance = torch.sigmoid(distance)\n",
    "        \n",
    "#         return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Define the architecture for the Siamese network\n",
    "        self.fc1 = nn.Linear(256*256, 128)  # Adjust input size based on input dimensions\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output size 1 for binary classification\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Flatten the input tensors\n",
    "        input1 = input1.view(input1.size(0), -1)\n",
    "        input2 = input2.view(input2.size(0), -1)\n",
    "        # Forward pass through the Siamese network\n",
    "        output1 = F.relu(self.fc1(input1))\n",
    "        output1 = F.relu(self.fc2(output1))\n",
    "        output2 = F.relu(self.fc1(input2))\n",
    "        output2 = F.relu(self.fc2(output2))\n",
    "        return output1, output2\n",
    "\n",
    "# Initialize Siamese network\n",
    "siamese_net = SiameseNetwork()\n",
    "siamese_net = siamese_net.cuda()  # Move the network to GPU\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
