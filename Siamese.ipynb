{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change detection (invariant to angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) # should be True\n",
    "# t = torch.rand(10, 10).cuda()\n",
    "# print(t.device) # should be CUDA\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with saggital midpoint images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image_if_not_exist(directory, output_size=(256, 256), second_dir='./data/heatmaps'):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\"nii_mask.nii.gz\"):\n",
    "                # Construct input and output paths\n",
    "                input_path = os.path.join(root, filename)\n",
    "                output_path = os.path.join(root, os.path.splitext(filename)[0] + \"saggital_view\" + \".jpg\")\n",
    "\n",
    "                # Check if output image already exists\n",
    "                if os.path.exists(output_path):\n",
    "                    print(f\"Image {output_path} already exists, skipping...\") \n",
    "                    continue\n",
    "                # Saggital - 0, Coronal - 1, Axial - 2\n",
    "                # Load NIfTI data\n",
    "                nifti_data = nib.load(input_path)\n",
    "                image_data = nifti_data.get_fdata()\n",
    "\n",
    "                slice_index = image_data.shape[0] // 2\n",
    "                image_slice = image_data[slice_index, :, :]\n",
    "\n",
    "                # Normalize intensity values\n",
    "                min_intensity = np.min(image_slice)\n",
    "                max_intensity = np.max(image_slice)\n",
    "                image_slice_normalized = (image_slice - min_intensity) / (max_intensity - min_intensity)\n",
    "\n",
    "                # Resize the slice to the specified output size\n",
    "                image_slice_resized = np.array(Image.fromarray((image_slice_normalized * 255).astype(np.uint8)).resize(output_size))\n",
    "\n",
    "                # Convert to image format\n",
    "                image = Image.fromarray(image_slice_resized)\n",
    "\n",
    "                # Resize the image to the specified output size\n",
    "                image = image.resize(output_size)\n",
    "                output_dir = os.path.join(second_dir, filename.split('_')[0])\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                # Save the image\n",
    "                image.save(output_path)\n",
    "                image.save(os.path.join(f'{second_dir}/{filename.split(\"_\")[0]}', os.path.splitext(filename)[0] + \"saggital_view\" + \".jpg\"))\n",
    "                print(f\"Converted masked image {input_path} to {output_path} with size {output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ./data/raw/preop/BTC-preop/sub-PAT31/ses-preop/anat/sub-PAT31_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON09/ses-preop/anat/sub-CON09_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON03/ses-preop/anat/sub-CON03_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT25/ses-preop/anat/sub-PAT25_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT14/ses-preop/anat/sub-PAT14_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT05/ses-preop/anat/sub-PAT05_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON02/ses-preop/anat/sub-CON02_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT26/ses-preop/anat/sub-PAT26_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT16/ses-preop/anat/sub-PAT16_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT01/ses-preop/anat/sub-PAT01_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT24/ses-preop/anat/sub-PAT24_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT13/ses-preop/anat/sub-PAT13_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON06/ses-preop/anat/sub-CON06_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON01/ses-preop/anat/sub-CON01_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT02/ses-preop/anat/sub-PAT02_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON08/ses-preop/anat/sub-CON08_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT10/ses-preop/anat/sub-PAT10_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT19/ses-preop/anat/sub-PAT19_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON04/ses-preop/anat/sub-CON04_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT17/ses-preop/anat/sub-PAT17_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT27/ses-preop/anat/sub-PAT27_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT07/ses-preop/anat/sub-PAT07_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON11/ses-preop/anat/sub-CON11_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON07/ses-preop/anat/sub-CON07_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT15/ses-preop/anat/sub-PAT15_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT29/ses-preop/anat/sub-PAT29_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT08/ses-preop/anat/sub-PAT08_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON10/ses-preop/anat/sub-CON10_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT23/ses-preop/anat/sub-PAT23_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT20/ses-preop/anat/sub-PAT20_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT22/ses-preop/anat/sub-PAT22_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT06/ses-preop/anat/sub-PAT06_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-CON05/ses-preop/anat/sub-CON05_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT03/ses-preop/anat/sub-PAT03_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT11/ses-preop/anat/sub-PAT11_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/preop/BTC-preop/sub-PAT28/ses-preop/anat/sub-PAT28_ses-preop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "dir = \"./data/raw/preop/BTC-preop\"\n",
    "output_size = (256, 256)  # Specify the desired output size\n",
    "convert_to_image_if_not_exist(dir, output_size, 'data/heatmaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ./data/raw/postop/BTC-postop/sub-CON09/ses-postop/anat/sub-CON09_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON03/ses-postop/anat/sub-CON03_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT25/ses-postop/anat/sub-PAT25_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT05/ses-postop/anat/sub-PAT05_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON02/ses-postop/anat/sub-CON02_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT26/ses-postop/anat/sub-PAT26_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT16/ses-postop/anat/sub-PAT16_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT01/ses-postop/anat/sub-PAT01_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT24/ses-postop/anat/sub-PAT24_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT13/ses-postop/anat/sub-PAT13_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON06/ses-postop/anat/sub-CON06_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT02/ses-postop/anat/sub-PAT02_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON08/ses-postop/anat/sub-CON08_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT10/ses-postop/anat/sub-PAT10_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON04/ses-postop/anat/sub-CON04_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT17/ses-postop/anat/sub-PAT17_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT07/ses-postop/anat/sub-PAT07_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON11/ses-postop/anat/sub-CON11_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON07/ses-postop/anat/sub-CON07_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT15/ses-postop/anat/sub-PAT15_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT08/ses-postop/anat/sub-PAT08_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON10/ses-postop/anat/sub-CON10_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT23/ses-postop/anat/sub-PAT23_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT20/ses-postop/anat/sub-PAT20_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT06/ses-postop/anat/sub-PAT06_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-CON05/ses-postop/anat/sub-CON05_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT03/ses-postop/anat/sub-PAT03_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT11/ses-postop/anat/sub-PAT11_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n",
      "Image ./data/raw/postop/BTC-postop/sub-PAT28/ses-postop/anat/sub-PAT28_ses-postop_T1w.nii_mask.niisaggital_view.jpg already exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "dir = \"./data/raw/postop/BTC-postop\"\n",
    "output_size = (256, 256)  # Specify the desired output size\n",
    "convert_to_image_if_not_exist(dir, output_size, second_dir='data/heatmaps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageSets(Dataset):\n",
    "    \"\"\"\n",
    "    Image dataset for each subject in the dataset\n",
    "    creating only 'correct' pairs for now\n",
    "    TODO: create 'incorrect' pairs\n",
    "\n",
    "    Works by passing preop or postop directory to the class\n",
    "    and finds the corresponding image in the other dir and labels\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for filename in files:\n",
    "                if filename.endswith(\"saggital_view.jpg\"):\n",
    "                    img_1 = Image.open(os.path.join(root, filename))\n",
    "                    ## finds the corresponding image in the other dir\n",
    "                    try:\n",
    "                        if \"preop\" in root:\n",
    "                            img_2 = Image.open(os.path.join(root.replace(\"preop\", \"postop\"), filename.replace(\"preop\", \"postop\")))\n",
    "                        else:\n",
    "                            img_2 = Image.open(os.path.join(root.replace(\"postop\", \"preop\"), filename.replace(\"postop\", \"preop\")))\n",
    "                        if \"-CON\" in filename:\n",
    "                            # print(\"control for \", filename)\n",
    "                            self.data.append((img_1, img_2, 1, filename)) # Similar\n",
    "                        elif \"-PAT\" in filename:\n",
    "                            self.data.append((img_1, img_2, 0, filename)) # Dissimalar\n",
    "                        else:\n",
    "                            print(f\"Invalid filename: {filename}\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Matching subject (pre and post) not found for {filename}\")\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            img1_file = self.transform(self.data[idx][0])\n",
    "            img2_file = self.transform(self.data[idx][1])\n",
    "        return (img1_file, img2_file, self.data[idx][2], self.data[idx][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Define the architecture for the Siamese network\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(131072, 128)  # Adjust input size based on input dimensions\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Forward pass through the Siamese network\n",
    "        output1 = F.relu(self.bn1(self.conv1(input1)))\n",
    "        output1 = F.max_pool2d(output1, kernel_size=2, stride=2)\n",
    "        output1 = F.relu(self.bn2(self.conv2(output1)))\n",
    "        output1 = F.max_pool2d(output1, kernel_size=2, stride=2)\n",
    "        output1 = F.relu(self.bn3(self.conv3(output1)))\n",
    "        output1 = F.max_pool2d(output1, kernel_size=2, stride=2)\n",
    "\n",
    "        output2 = F.relu(self.bn1(self.conv1(input2)))\n",
    "        output2 = F.max_pool2d(output2, kernel_size=2, stride=2)\n",
    "        output2 = F.relu(self.bn2(self.conv2(output2)))\n",
    "        output2 = F.max_pool2d(output2, kernel_size=2, stride=2)\n",
    "        output2 = F.relu(self.bn3(self.conv3(output2)))\n",
    "        output2 = F.max_pool2d(output2, kernel_size=2, stride=2)\n",
    "\n",
    "        return output1, output2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstractiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self,margin =2.0,dist_flag='l2'):\n",
    "        super(ConstractiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.dist_flag = dist_flag\n",
    "\n",
    "    def various_distance(self,out_vec_t0,out_vec_t1):\n",
    "\n",
    "        if self.dist_flag == 'l2':\n",
    "            distance = F.pairwise_distance(out_vec_t0,out_vec_t1,p=2)\n",
    "        if self.dist_flag == 'l1':\n",
    "            distance = F.pairwise_distance(out_vec_t0,out_vec_t1,p=1)\n",
    "        if self.dist_flag == 'cos':\n",
    "            similarity = F.cosine_similarity(out_vec_t0,out_vec_t1)\n",
    "            distance = 1 - 2 * similarity/np.pi\n",
    "        return distance\n",
    "\n",
    "    def forward(self,out_vec_t0,out_vec_t1,label):\n",
    "\n",
    "        #distance = F.pairwise_distance(out_vec_t0,out_vec_t1,p=2)\n",
    "        distance = self.various_distance(out_vec_t0,out_vec_t1)\n",
    "        #distance = 1 - F.cosine_similarity(out_vec_t0,out_vec_t1)\n",
    "        constractive_loss = torch.sum((1-label)*torch.pow(distance,2 ) + \\\n",
    "                                       label * torch.pow(torch.clamp(self.margin - distance, min=0.0),2))\n",
    "        return constractive_loss\n",
    "    \n",
    "class ConstractiveThresholdHingeLoss(nn.Module):\n",
    "\n",
    "    def __init__(self,hingethresh=0.0,margin=2.0):\n",
    "        super(ConstractiveThresholdHingeLoss, self).__init__()\n",
    "        self.threshold = hingethresh\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self,out_vec_t0,out_vec_t1,label):\n",
    "\n",
    "        distance = F.pairwise_distance(out_vec_t0,out_vec_t1,p=2)\n",
    "        similar_pair = torch.clamp(distance - self.threshold,min=0.0)\n",
    "        dissimilar_pair = torch.clamp(self.margin- distance,min=0.0)\n",
    "        #dissimilar_pair = torch.clamp(self.margin-(distance-self.threshold),min=0.0)\n",
    "        constractive_thresh_loss = torch.sum(\n",
    "            (1-label)* torch.pow(similar_pair,2) + label * torch.pow(dissimilar_pair,2)\n",
    "        )\n",
    "        return constractive_thresh_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def check_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "def various_distance(out_vec_t0, out_vec_t1,dist_flag):\n",
    "    if dist_flag == 'l2':\n",
    "        distance = F.pairwise_distance(out_vec_t0, out_vec_t1, p=2)\n",
    "    if dist_flag == 'l1':\n",
    "        distance = F.pairwise_distance(out_vec_t0, out_vec_t1, p=1)\n",
    "    if dist_flag == 'cos':\n",
    "        distance = 1 - F.cosine_similarity(out_vec_t0, out_vec_t1)\n",
    "    return distance\n",
    "\n",
    "def single_layer_similar_heatmap_visual(output_t0,output_t1,save_change_map_dir,filename,dist_flag):\n",
    "\n",
    "    interp = nn.Upsample(size=[512,512], mode='bilinear')\n",
    "    n, c, h, w = output_t0.data.shape\n",
    "    out_t0_rz = torch.transpose(output_t0.view(c, h * w), 1, 0)\n",
    "    out_t1_rz = torch.transpose(output_t1.view(c, h * w), 1, 0)\n",
    "    distance = various_distance(out_t0_rz,out_t1_rz,dist_flag=dist_flag)\n",
    "    similar_distance_map = distance.view(h,w).data.cpu().numpy()\n",
    "    similar_distance_map_rz = interp(torch.from_numpy(similar_distance_map[np.newaxis, np.newaxis, :]))\n",
    "    similar_dis_map_colorize = cv2.applyColorMap(np.uint8(255 * similar_distance_map_rz.data.cpu().numpy()[0][0]), cv2.COLORMAP_JET)\n",
    "    check_dir(save_change_map_dir)\n",
    "    # save_change_map_dir_layer = os.path.join(save_change_map_dir,layer_flag)\n",
    "    # check_dir(save_change_map_dir_layer)\n",
    "    save_weight_fig_dir = os.path.join(save_change_map_dir, filename + '.jpg')\n",
    "    cv2.imwrite(save_weight_fig_dir, similar_dis_map_colorize)\n",
    "    return similar_distance_map_rz.data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(siamese_net,  optimizer, criterion, epochs=100, patience=3, save_dir='models'):\n",
    "    default_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "    BATCH_SIZE = 1\n",
    "    train_data = imageSets(\"./data/raw/preop/BTC-preop\", transform=default_transform)\n",
    "    loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    siamese_net.train()\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    total_loss = 0\n",
    "    best_loss = float('inf')\n",
    "    consecutive_no_improvement = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0000\n",
    "        for i, (img1_set, img2_set, label, filename) in enumerate(loader):\n",
    "            # img1_set = img1_set.cuda()\n",
    "            # img2_set = img2_set.cuda()\n",
    "            # label = label.cuda()'\n",
    "            ##TODO: \n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = siamese_net(img1_set, img2_set)\n",
    "            loss = criterion(output1, output2, label)  # Add unsqueeze to match output shape\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(loss.item())\n",
    "            epoch_loss += loss.item()\n",
    "        print('Epoch [%d/%d], Loss: %.4f' % (epoch+1, epochs, epoch_loss))\n",
    "                # Check for early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            consecutive_no_improvement = 0\n",
    "            # Save the best model\n",
    "            save_path = os.path.join(save_dir, 'best_model.pth')\n",
    "            torch.save(siamese_net.state_dict(), save_path)\n",
    "            print(f'Saved best model to {save_path}')\n",
    "        else:\n",
    "            consecutive_no_improvement += 1\n",
    "            if consecutive_no_improvement >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1} as no improvement for {patience} consecutive epochs.')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the best model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Siamese network\n",
    "siamese_net = SiameseNetwork()\n",
    "# siamese_net = siamese_net.cuda()  # Move the network to GPU\n",
    "\n",
    "# Define loss function and optimizer\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)\n",
    "save_dir = './models'\n",
    "if os.path.exists(os.path.join(save_dir, 'best_model.pth')):\n",
    "    siamese_net.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pth')))\n",
    "    print('Loaded the best model')\n",
    "else:\n",
    "    criterion = ConstractiveLoss(margin=0.0)\n",
    "    optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)\n",
    "    # Train the Siamese network\n",
    "    train(siamese_net,  optimizer, criterion, epochs=100, patience=3, save_dir='./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict(siamese_net, image1, image2, threshold=0.5):\n",
    "    siamese_net.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output1, output2 = siamese_net(image1, image2)\n",
    "        distance1 = F.pairwise_distance(output1, output2,p=2)  # Compute the distance between the embeddings\n",
    "        distance = torch.dist(output1, output2, p=2)\n",
    "        #print(f\"Distance: {distance1}\")\n",
    "        similarity_score = 1 - distance.item()  # Convert distance to similarity score\n",
    "        prediction = similarity_score > threshold  # Determine if the pair is similar based on the threshold\n",
    "    return prediction, similarity_score, output1, output2, distance.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching subject (pre and post) not found for sub-PAT31_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "Matching subject (pre and post) not found for sub-PAT14_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "Matching subject (pre and post) not found for sub-CON01_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "Matching subject (pre and post) not found for sub-PAT19_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "Matching subject (pre and post) not found for sub-PAT27_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "Matching subject (pre and post) not found for sub-PAT29_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "Matching subject (pre and post) not found for sub-PAT22_ses-preop_T1w.nii_mask.niisaggital_view.jpg\n",
      "The pair is similar with a similarity score of: 0.6258323192596436  label: tensor([1])  distance: 0.37416768074035645\n",
      "The pair is dissimilar with a similarity score of: -0.3267233371734619  label: tensor([1])  distance: 1.326723337173462\n",
      "The pair is dissimilar with a similarity score of: 0.1371658444404602  label: tensor([0])  distance: 0.8628341555595398\n",
      "The pair is dissimilar with a similarity score of: 0.2450198531150818  label: tensor([0])  distance: 0.7549801468849182\n",
      "The pair is dissimilar with a similarity score of: -4.26292610168457  label: tensor([1])  distance: 5.26292610168457\n",
      "The pair is similar with a similarity score of: 0.6666672825813293  label: tensor([0])  distance: 0.33333271741867065\n",
      "The pair is dissimilar with a similarity score of: 0.27748245000839233  label: tensor([0])  distance: 0.7225175499916077\n",
      "The pair is similar with a similarity score of: 0.6926134824752808  label: tensor([0])  distance: 0.30738651752471924\n",
      "The pair is similar with a similarity score of: 0.925024226307869  label: tensor([0])  distance: 0.07497577369213104\n",
      "The pair is similar with a similarity score of: 0.8913401216268539  label: tensor([0])  distance: 0.10865987837314606\n",
      "The pair is similar with a similarity score of: 0.7206973135471344  label: tensor([1])  distance: 0.2793026864528656\n",
      "The pair is similar with a similarity score of: 0.7068455815315247  label: tensor([0])  distance: 0.29315441846847534\n",
      "The pair is dissimilar with a similarity score of: -0.19847524166107178  label: tensor([1])  distance: 1.1984752416610718\n",
      "The pair is similar with a similarity score of: 0.8534274250268936  label: tensor([0])  distance: 0.14657257497310638\n",
      "The pair is dissimilar with a similarity score of: -2.3302526473999023  label: tensor([1])  distance: 3.3302526473999023\n",
      "The pair is dissimilar with a similarity score of: 0.45728468894958496  label: tensor([0])  distance: 0.542715311050415\n",
      "The pair is similar with a similarity score of: 0.5816021263599396  label: tensor([0])  distance: 0.4183978736400604\n",
      "The pair is dissimilar with a similarity score of: -3.18135929107666  label: tensor([1])  distance: 4.18135929107666\n",
      "The pair is similar with a similarity score of: 0.8661728203296661  label: tensor([1])  distance: 0.13382717967033386\n",
      "The pair is similar with a similarity score of: 0.7006886899471283  label: tensor([0])  distance: 0.2993113100528717\n",
      "The pair is similar with a similarity score of: 0.8514153212308884  label: tensor([0])  distance: 0.14858467876911163\n",
      "The pair is similar with a similarity score of: 0.7634559720754623  label: tensor([1])  distance: 0.23654402792453766\n",
      "The pair is similar with a similarity score of: 0.8015037477016449  label: tensor([0])  distance: 0.1984962522983551\n",
      "The pair is dissimilar with a similarity score of: -0.7787048816680908  label: tensor([0])  distance: 1.7787048816680908\n",
      "The pair is similar with a similarity score of: 0.7667009681463242  label: tensor([0])  distance: 0.23329903185367584\n",
      "The pair is similar with a similarity score of: 0.8503969013690948  label: tensor([1])  distance: 0.14960309863090515\n",
      "The pair is dissimilar with a similarity score of: 0.16916757822036743  label: tensor([0])  distance: 0.8308324217796326\n",
      "The pair is similar with a similarity score of: 0.6218603253364563  label: tensor([0])  distance: 0.3781396746635437\n",
      "The pair is dissimilar with a similarity score of: -0.515566349029541  label: tensor([0])  distance: 1.515566349029541\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "# label 1 is similar, 0 is dissimilar\n",
    "BATCH_SIZE = 1\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "train_data = imageSets(\"./data/raw/preop/BTC-preop\", transform=default_transform)\n",
    "loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for i, (img1_set, img2_set, label, filename) in enumerate(loader):\n",
    "    orig_filename = os.path.splitext(filename[0])[0]\n",
    "    patient_id = orig_filename.split(\"_\")[0]\n",
    "    is_similar, similarity_score, output1, output2, distance = predict(siamese_net, img1_set, img2_set)\n",
    "    single_layer_similar_heatmap_visual(output1,output2,f\"./data/heatmaps/{patient_id}\", f'{patient_id}_predic_{label}','l2')\n",
    "    # Printing the prediction result\n",
    "    if is_similar:\n",
    "        print(\"The pair is similar with a similarity score of:\", similarity_score, \" label:\", label, \" distance:\", distance)\n",
    "    else:\n",
    "        print(\"The pair is dissimilar with a similarity score of:\", similarity_score, \" label:\", label, \" distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_preop = nib.load(\"./data/raw/preop/sub-CON02_ses-preop_T1w.nii.gz\")\n",
    "# raw_postop = nib.load(\"./data/raw/postop/sub-CON02_ses-postop_T1w.nii.gz\")\n",
    "\n",
    "# proc_preop = nib.load(\"./data/processed/preop/fa.nii.gz\")\n",
    "# proc_postop = nib.load(\"./data/processed/postop/fa.nii.gz\")\n",
    "\n",
    "# # This apparently returns voxel level of the data\n",
    "# data_raw_preop= raw_preop.get_fdata()\n",
    "# data_raw_postop= raw_postop.get_fdata()\n",
    "\n",
    "# data_proc_preop= proc_preop.get_fdata()\n",
    "# data_proc_postop= proc_postop.get_fdata()\n",
    "\n",
    "# print(data_raw_preop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20693/2275318329.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  raw_pairs_tensor = torch.tensor(raw_pairs, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# def make_pairs():\n",
    "#     pass\n",
    "import sys\n",
    "\n",
    "mock_pairs = [(data_raw_preop, data_raw_postop), (data_raw_preop, data_raw_preop), (data_raw_postop, data_raw_postop)]\n",
    "mock_labels = [1, 0, 0]\n",
    "\n",
    "raw_pairs = mock_pairs\n",
    "raw_labels = mock_labels\n",
    "# Convert the processed data into PyTorch tensors\n",
    "raw_pairs_tensor = torch.tensor(raw_pairs, dtype=torch.float32)\n",
    "raw_labels_tensor = torch.tensor(raw_labels, dtype=torch.float32)\n",
    "print(sys.getsizeof(raw_pairs_tensor))\n",
    "# print(raw_pairs_tensor)\n",
    "\n",
    "# Create DataLoader for training\n",
    "# raw_dataset = TensorDataset(raw_pairs_tensor, raw_labels_tensor)\n",
    "# raw_loader = DataLoader(raw_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         self.subnetwork = SubNetwork(input_size, hidden_size, output_size)\n",
    "    \n",
    "#     def forward(self, input1, input2):\n",
    "#         # Pass inputs through the subnetwork\n",
    "#         output1 = self.subnetwork(input1)\n",
    "#         output2 = self.subnetwork(input2)\n",
    "        \n",
    "#         # Compute the Euclidean distance between the outputs\n",
    "#         distance = torch.sqrt(torch.sum(torch.pow(output1 - output2, 2), dim=1))\n",
    "        \n",
    "#         # Normalize the distance to [0, 1] range\n",
    "#         distance = torch.sigmoid(distance)\n",
    "        \n",
    "#         return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Define the architecture for the Siamese network\n",
    "        self.fc1 = nn.Linear(256*256, 128)  # Adjust input size based on input dimensions\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output size 1 for binary classification\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Flatten the input tensors\n",
    "        input1 = input1.view(input1.size(0), -1)\n",
    "        input2 = input2.view(input2.size(0), -1)\n",
    "        # Forward pass through the Siamese network\n",
    "        output1 = F.relu(self.fc1(input1))\n",
    "        output1 = F.relu(self.fc2(output1))\n",
    "        output2 = F.relu(self.fc1(input2))\n",
    "        output2 = F.relu(self.fc2(output2))\n",
    "        return output1, output2\n",
    "\n",
    "# Initialize Siamese network\n",
    "siamese_net = SiameseNetwork()\n",
    "siamese_net = siamese_net.cuda()  # Move the network to GPU\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
