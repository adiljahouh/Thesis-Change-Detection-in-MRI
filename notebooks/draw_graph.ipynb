{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class DeepLabV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepLabV3, self).__init__()\n",
    "        \n",
    "        # Initial layers (unchanged)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Downscale 256x256 -> 128x128\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Downscale 128x128 -> 64x64\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Downscale 64x64 -> 32x32\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True)  # Keep 32x32\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Replace the old atrous pyramid pooling with DeepLabV3-style ASPP\n",
    "        self.aspp_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.aspp_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=6, dilation=6, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.aspp_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=12, dilation=12, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.aspp_conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=18, dilation=18, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        # Global pooling branch\n",
    "        self.aspp_pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(256, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        # Final 1x1 conv after concatenation\n",
    "        self.aspp_final = nn.Sequential(\n",
    "            nn.Conv2d(512 * 5, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.embedding_layer = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1)\n",
    "\n",
    "    def forward_branch(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        conv3_feature = self.conv3(x)\n",
    "        conv4_feature = self.conv4(conv3_feature)\n",
    "        conv5_feature = self.conv5(conv4_feature)\n",
    "        \n",
    "        # ASPP forward pass\n",
    "        aspp1 = self.aspp_conv1(conv5_feature)\n",
    "        aspp2 = self.aspp_conv2(conv5_feature)\n",
    "        aspp3 = self.aspp_conv3(conv5_feature)\n",
    "        aspp4 = self.aspp_conv4(conv5_feature)\n",
    "        \n",
    "        # Global pooling branch\n",
    "        pool = self.aspp_pool(conv5_feature)\n",
    "        pool = F.interpolate(pool, size=conv5_feature.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Concatenate all branches\n",
    "        aspp_out = torch.cat([aspp1, aspp2, aspp3, aspp4, pool], dim=1)\n",
    "        aspp_out = self.aspp_final(aspp_out)\n",
    "        \n",
    "        # Final embedding\n",
    "        embedding_feature = self.embedding_layer(aspp_out)\n",
    "        \n",
    "        return conv4_feature, conv5_feature, embedding_feature\n",
    "\n",
    "    def normalize(self, x, scale=1.0, dim=1):\n",
    "        norm = x.pow(2).sum(dim=dim, keepdim=True).clamp(min=1e-12).rsqrt()\n",
    "        return scale * x * norm\n",
    "\n",
    "    def forward(self, x1, mode='train'):\n",
    "        out1 = self.forward_branch(x1)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adil/Documents/TUE/ThesisPrepPhase/myProject/.conda/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adil/Documents/TUE/ThesisPrepPhase/myProject/.conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/siamese_simple.png'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchview import draw_graph\n",
    "# Load the DeepLabV3 Siamese model\n",
    "model = DeepLabV3()\n",
    "\n",
    "# Simulated input (batch_size=16, grayscale input)\n",
    "x = torch.randn(16, 1, 256, 256)\n",
    "\n",
    "# Generate model visualization (handles two inputs correctly)\n",
    "model_graph = draw_graph(model, input_data=x, expand_nested=True, depth=1)\n",
    "\n",
    "# Show visualization\n",
    "model_graph.visual_graph.render(\"images/siamese_simple\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchgraph see error message",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/TUE/ThesisPrepPhase/myProject/.conda/lib/python3.11/site-packages/torchview/torchview.py:256\u001b[0m, in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 256\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Mapping):\n",
      "File \u001b[0;32m~/Documents/TUE/ThesisPrepPhase/myProject/.conda/lib/python3.11/site-packages/torchview/recorder_tensor.py:146\u001b[0m, in \u001b[0;36mmodule_forward_wrapper.<locals>._module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# TODO: check if output contains RecorderTensor\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# this seems not to be necessary so far\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m_orig_module_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m model_graph\u001b[38;5;241m.\u001b[39mcontext_tracker[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_depth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cur_depth\n",
      "File \u001b[0;32m~/Documents/TUE/ThesisPrepPhase/myProject/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/TUE/ThesisPrepPhase/myProject/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: DeepLabV3.forward() got an unexpected keyword argument 'show_attrs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate model visualization (handles two inputs correctly)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model_graph \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_nested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Show visualization\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model_graph\u001b[38;5;241m.\u001b[39mvisual_graph\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/siamese_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/TUE/ThesisPrepPhase/myProject/.conda/lib/python3.11/site-packages/torchview/torchview.py:220\u001b[0m, in \u001b[0;36mdraw_graph\u001b[0;34m(model, input_data, input_size, graph_name, depth, device, dtypes, mode, strict, expand_nested, graph_dir, hide_module_functions, hide_inner_tensors, roll, show_shapes, save_graph, filename, directory, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m input_recorder_tensor, kwargs_record_tensor, input_nodes \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    212\u001b[0m     input_data, input_size, kwargs, device, dtypes\n\u001b[1;32m    213\u001b[0m )\n\u001b[1;32m    215\u001b[0m model_graph \u001b[38;5;241m=\u001b[39m ComputationGraph(\n\u001b[1;32m    216\u001b[0m     visual_graph, input_nodes, show_shapes, expand_nested,\n\u001b[1;32m    217\u001b[0m     hide_inner_tensors, hide_module_functions, roll, depth\n\u001b[1;32m    218\u001b[0m )\n\u001b[0;32m--> 220\u001b[0m \u001b[43mforward_prop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_recorder_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_record_tensor\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m model_graph\u001b[38;5;241m.\u001b[39mfill_visual_graph()\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_graph:\n",
      "File \u001b[0;32m~/Documents/TUE/ThesisPrepPhase/myProject/.conda/lib/python3.11/site-packages/torchview/torchview.py:264\u001b[0m, in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown input type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchgraph see error message\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(saved_model_mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchgraph see error message"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchview import draw_graph\n",
    "# Load the DeepLabV3 Siamese model\n",
    "model = DeepLabV3()\n",
    "\n",
    "# Simulated input (batch_size=16, grayscale input)\n",
    "x = torch.randn(16, 1, 256, 256)\n",
    "\n",
    "# Generate model visualization (handles two inputs correctly)\n",
    "model_graph = draw_graph(model, input_data=x, expand_nested=True, depth=6)\n",
    "\n",
    "# Show visualization\n",
    "model_graph.visual_graph.render(\"images/siamese_depth\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
