{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class DeepLabV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepLabV3, self).__init__()\n",
    "        \n",
    "        # Initial layers (unchanged)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Downscale 256x256 -> 128x128\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Downscale 128x128 -> 64x64\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Downscale 64x64 -> 32x32\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True)  # Keep 32x32\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, dilation=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Replace the old atrous pyramid pooling with DeepLabV3-style ASPP\n",
    "        self.aspp_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.aspp_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=6, dilation=6, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.aspp_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=12, dilation=12, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.aspp_conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=18, dilation=18, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        # Global pooling branch\n",
    "        self.aspp_pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(256, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        \n",
    "        # Final 1x1 conv after concatenation\n",
    "        self.aspp_final = nn.Sequential(\n",
    "            nn.Conv2d(512 * 5, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.embedding_layer = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1)\n",
    "\n",
    "    def forward_branch(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        conv3_feature = self.conv3(x)\n",
    "        conv4_feature = self.conv4(conv3_feature)\n",
    "        conv5_feature = self.conv5(conv4_feature)\n",
    "        \n",
    "        # ASPP forward pass\n",
    "        aspp1 = self.aspp_conv1(conv5_feature)\n",
    "        aspp2 = self.aspp_conv2(conv5_feature)\n",
    "        aspp3 = self.aspp_conv3(conv5_feature)\n",
    "        aspp4 = self.aspp_conv4(conv5_feature)\n",
    "        \n",
    "        # Global pooling branch\n",
    "        pool = self.aspp_pool(conv5_feature)\n",
    "        pool = F.interpolate(pool, size=conv5_feature.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Concatenate all branches\n",
    "        aspp_out = torch.cat([aspp1, aspp2, aspp3, aspp4, pool], dim=1)\n",
    "        aspp_out = self.aspp_final(aspp_out)\n",
    "        \n",
    "        # Final embedding\n",
    "        embedding_feature = self.embedding_layer(aspp_out)\n",
    "        \n",
    "        return conv4_feature, conv5_feature, embedding_feature\n",
    "\n",
    "    def normalize(self, x, scale=1.0, dim=1):\n",
    "        norm = x.pow(2).sum(dim=dim, keepdim=True).clamp(min=1e-12).rsqrt()\n",
    "        return scale * x * norm\n",
    "\n",
    "    def forward(self, x1, mode='train'):\n",
    "        out1 = self.forward_branch(x1)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adil/Documents/TUE/ThesisPrepPhase/myProject/.conda/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adil/Documents/TUE/ThesisPrepPhase/myProject/.conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/siamese_simple.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchview import draw_graph\n",
    "# Load the DeepLabV3 Siamese model\n",
    "model = DeepLabV3()\n",
    "\n",
    "# Simulated input (batch_size=16, grayscale input)\n",
    "x = torch.randn(16, 1, 256, 256)\n",
    "\n",
    "# Generate model visualization (handles two inputs correctly)\n",
    "model_graph = draw_graph(model, input_data=x, expand_nested=True, depth=1)\n",
    "\n",
    "# Show visualization\n",
    "model_graph.visual_graph.render(\"images/siamese_simple\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DeepLabV3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchview\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_graph\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the DeepLabV3 Siamese model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDeepLabV3\u001b[49m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Simulated input (batch_size=16, grayscale input)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DeepLabV3' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchview import draw_graph\n",
    "# Load the DeepLabV3 Siamese model\n",
    "model = DeepLabV3()\n",
    "\n",
    "# Simulated input (batch_size=16, grayscale input)\n",
    "x = torch.randn(16, 1, 256, 256)\n",
    "\n",
    "# Generate model visualization (handles two inputs correctly)\n",
    "model_graph = draw_graph(model, input_data=x, expand_nested=False, depth=6)\n",
    "\n",
    "# Show visualization\n",
    "model_graph.visual_graph.render(\"images/siamese_depth\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
